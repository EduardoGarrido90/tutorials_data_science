{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMpXb03yojt58b0DA6HLFjM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EduardoGarrido90/tutorials_data_science/blob/main/California_MLR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple Linear Regression model of the California Housing Dataset\n",
        "\n",
        "# MODEL SPECIFICATION AND ESTIMATION\n",
        "\n",
        "The steps to estimate a MLR model wrt data are always the same ones.\n",
        "\n",
        "1. First, we load the data. No data, no party!\n",
        "2. We specify the model equation with respect to the variables of the data.\n",
        "3. We fit the model and show the summary.\n",
        "\n",
        "Then, we show two results:\n",
        "\n",
        "1. The summary of the econometric model."
      ],
      "metadata": {
        "id": "exkgNKAk3NWA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPAiYbM-z-sw"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "import pandas as pd\n",
        "\n",
        "# Load California housing dataset\n",
        "california_data = fetch_california_housing()\n",
        "df_california = pd.DataFrame(california_data.data, columns=california_data.feature_names)\n",
        "df_california['MedHouseVal'] = california_data.target  # Median house value\n",
        "\n",
        "# Selecting a few predictors for the regression model\n",
        "predictors_california = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
        "df_california_subset = df_california[predictors_california + ['MedHouseVal']]\n",
        "\n",
        "# Linear regression model using statsmodels\n",
        "model_california = smf.ols('MedHouseVal ~ MedInc + HouseAge + AveRooms + AveBedrms + Population + AveOccup + Latitude + Longitude', data=df_california_subset)\n",
        "results = model_california.fit()\n",
        "\n",
        "# Summary of the model\n",
        "summary_california = results.summary()\n",
        "summary_california\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. The equation of the model. Just modifying the dependent variable, you can modify this code to suit your particular needs."
      ],
      "metadata": {
        "id": "_6OExWBn3n-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Latex\n",
        "# Corrected approach to generate the LaTeX representation of the model equation\n",
        "dependent_var = 'MEDV'  # Name of the dependent variable\n",
        "latex_equation = dependent_var + ' = '\n",
        "for i, (param, value) in enumerate(zip(results.params.index, results.params.values)):\n",
        "\n",
        "    if param == 'Intercept':\n",
        "        latex_equation += f'{value:.4f}'\n",
        "    else:\n",
        "        sign = '+' if value >= 0 else '-'\n",
        "        latex_equation += f' {sign} {abs(value):.4f} \\\\times {param}'\n",
        "\n",
        "latex_equation = '$' + latex_equation + '$'\n",
        "display(Latex(latex_equation))\n",
        "\n"
      ],
      "metadata": {
        "id": "5xWKTyje2XfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL VALIDATION\n",
        "\n",
        "**Checking multicolinearity**\n",
        "\n",
        "Variance Inflation Factor (VIF): The VIF quantifies how much the variance of an estimated regression coefficient increases if your predictors are correlated. A VIF above 5-10 indicates high multicollinearity."
      ],
      "metadata": {
        "id": "dhhp5c4l5XO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Calculate VIFs for each variable\n",
        "X = df_california_subset[predictors_california]\n",
        "X['Intercept'] = 1\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Feature\"] = X.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]\n",
        "print(vif_data)"
      ],
      "metadata": {
        "id": "awdgHPcv5YDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking linearity and heterocedasticity**\n",
        "\n",
        "A residual plot (residuals vs. fitted values) helps in checking the assumption of linearity and homoscedasticity (constant variance) of residuals.\n",
        "\n",
        "A normality test, such as the Shapiro-Wilk test, can be used to assess the normality of the residuals. Additionally, a QQ plot (quantile-quantile plot) can visually assess the normality."
      ],
      "metadata": {
        "id": "tPt6Xjqg6AkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Residual plot\n",
        "residuals = results.resid\n",
        "fitted = results.fittedvalues\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(fitted, residuals)\n",
        "plt.axhline(0, color='red', linestyle='--')\n",
        "plt.xlabel('Fitted values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residuals vs Fitted Values')\n",
        "plt.show()\n",
        "\n",
        "# Normality test and QQ plot\n",
        "shapiro_test = stats.shapiro(residuals)\n",
        "plt.figure(figsize=(5, 5))\n",
        "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
        "plt.title('QQ Plot')\n",
        "plt.show()\n",
        "\n",
        "vif_data, shapiro_test"
      ],
      "metadata": {
        "id": "T16bDUqF6CYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking Autocorrelation**\n",
        "\n",
        "Autocorrelation occurs when the residuals are not independent of each other. The Durbin-Watson test is commonly used to detect this.\n",
        "\n",
        "A Durbin-Watson statistic close to 2 suggests no autocorrelation; values below 1 or above 3 are a cause for concern."
      ],
      "metadata": {
        "id": "5OnBkbhK7CcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Durbin-Watson test for autocorrelation\n",
        "durbin_watson_statistic = sm.stats.stattools.durbin_watson(residuals)\n",
        "durbin_watson_statistic"
      ],
      "metadata": {
        "id": "GuQcksh77NSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking Endogeneity**\n",
        "\n",
        "Exogeneity implies that the predictors (independent variables) are not correlated with the error term. Violation of this assumption is known as endogeneity.\n",
        "\n",
        "One common method to test for exogeneity is to look for correlation between the residuals and the independent variables, which can suggest endogeneity issues."
      ],
      "metadata": {
        "id": "WDFk-Jpn7X3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cheking endogeneity\n",
        "correlation_data = pd.DataFrame()\n",
        "for predictor in predictors_california:\n",
        "    correlation_data[predictor] = [df_california_subset[predictor].corr(residuals)]\n",
        "\n",
        "correlation_data"
      ],
      "metadata": {
        "id": "g66dRRvk7nJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking specification**\n",
        "\n",
        "Plotting Residuals vs. Predictors: This helps in visually inspecting whether the relationship between predictors and the response variable is linear or if there are any obvious patterns or non-linear trends in the residuals."
      ],
      "metadata": {
        "id": "Ue6z2qRs8ek-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.diagnostic import linear_reset\n",
        "\n",
        "\n",
        "\n",
        "# Plotting residuals vs. predictors for visual inspection\n",
        "fig, axs = plt.subplots(nrows=3, ncols=3, figsize=(15, 10))\n",
        "axs = axs.flatten()\n",
        "for i, predictor in enumerate(predictors_california):\n",
        "    axs[i].scatter(df_california_subset[predictor], residuals)\n",
        "    axs[i].set_title(f'Residuals vs {predictor}')\n",
        "    axs[i].set_xlabel(predictor)\n",
        "    axs[i].set_ylabel('Residuals')\n",
        "\n",
        "# Adjust layout and show plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NUHAg6PK8kja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ramsey's RESET Test: This test is specifically designed to detect omitted variable bias and incorrect functional form. It tests whether higher-order terms (like squared or cubic terms) of the fitted values help in explaining the response variable."
      ],
      "metadata": {
        "id": "ZcJQO-rJ9IDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ramsey's RESET test for model specification\n",
        "reset_test = linear_reset(results, power=3, use_f=True)\n",
        "reset_test"
      ],
      "metadata": {
        "id": "JWokqRz78-Uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The RESET test results in an F-statistic of approximately 1098.23 with a very small p-value (almost 0).\n",
        "\n",
        "This significant p-value indicates that there is evidence of omitted variables or that the model may have an incorrect functional form, such as missing non-linear components."
      ],
      "metadata": {
        "id": "JGz3sLCy9OVO"
      }
    }
  ]
}